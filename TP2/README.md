# TP2 - Sistema de Scraping Distribuido

## Arquitectura
El sistema tiene dos servidores separados por responsabilidad:
- Servidor A (Asyncio): servidor HTTP asincrÃ³nico pensado para tareas I/O-bound (peticiones HTTP, red, disco).
- Servidor B (Multiprocessing): servidor TCP para tareas CPU-bound y procesamiento pesado, usa mÃºltiples workers.

## Setup
1. Crear entorno virtual:
   - Linux / macOS:
     ```
     python3 -m venv venv
     ```
   - Windows:
     ```
     python -m venv venv
     ```

2. Activar el entorno:
   - Linux / macOS:
     ```
     source venv/bin/activate
     ```
   - Windows:
     ```
     venv\Scripts\activate
     ```

3. Instalar dependencias:
   ```
   pip install -r requirements.txt
   ```

## EjecuciÃ³n
Se recomienda arrancar el servidor de procesamiento primero.

Terminal 1 â€” servidor B (Multiprocessing):
```
python server_processing.py
# o python3 server_processing.py
```

Terminal 2 â€” servidor A (Asyncio):
```
python server_scraping.py
# o python3 server_scraping.py
```

Al iniciar verÃ¡s:
- "ðŸš€ Servidor B (Multiprocessing) iniciando en 0.0.0.0:9090"
- "ðŸš€ Servidor A (Asyncio) iniciando en http://0.0.0.0:8080"

## Testing
Probar endpoint /health del Servidor A:
```
curl -s http://0.0.0.0:8080/health
# respuesta esperada: {"status":"ok","server":"A - Asyncio"}
```

## Estructura del Proyecto
```
TP2
â”œâ”€â”€ server_scraping.py
â”œâ”€â”€ server_processing.py
â”œâ”€â”€ client.py
â”œâ”€â”€ scraper
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ html_parser.py
â”‚   â”œâ”€â”€ metadata_extractor.py
â”‚   â””â”€â”€ async_http.py
â”œâ”€â”€ processor
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ screenshot.py
â”‚   â”œâ”€â”€ performance.py
â”‚   â””â”€â”€ image_processor.py
â”œâ”€â”€ common
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ protocol.py
â”‚   â””â”€â”€ serialization.py
â”œâ”€â”€ tests
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_scraper.py
â”‚   â””â”€â”€ test_processor.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```